# -*- coding: utf-8 -*-
"""COMP576_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SXthtFUTLX6mTOERONv_gP6pUAhcu_HQ
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from tqdm.notebook import tqdm
warnings.filterwarnings('ignore')
# %matplotlib inline

import tensorflow as tf
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input

import cv2 as cv
import math

!unzip -uq "/content/drive/MyDrive/archive.zip" -d "/content"

BASE_DIR = '/content/UTKFace'
# labels - age, gender, ethnicity
image_paths = []
race_labels = []
gender_labels = []

from tqdm.notebook import tqdm
import os
for filename in tqdm(os.listdir(BASE_DIR)):
    image_path = os.path.join(BASE_DIR, filename)
    temp = filename.split('_')
    gender = int(temp[1])
    if isinstance(temp[1],int) == True:
      race = int(temp[2])
    else:
      race = 4
    image_paths.append(image_path)
    race_labels.append(race)
    gender_labels.append(gender)

from tqdm import tqdm
from PIL import Image, ImageOps

def extract_features(images):
    features = []
    for image in tqdm(images):
        img = load_img(image, grayscale=False)
        img = img.resize((64, 64), Image.ANTIALIAS)
        img = np.array(img)
        features.append(img)
        
    features = np.array(features)
    # ignore this step if using RGB
    #features = features.reshape(len(features), 128, 128, 3)
    return features

#Visualize data by pandas
import pandas as pd

image_paths = pd.Series(list(image_paths), name = 'Images Path')
race_labels = pd.Series(list(race_labels), name = 'Race')
gender_labels = pd.Series(list(gender_labels), name = 'Genders')

dataframe = pd.concat([image_paths, race_labels, gender_labels], axis = 1)
dataframe

X = extract_features(dataframe['Images Path'])

#Normalize the images
X = X/255.0

y_gender = np.array(dataframe['Genders'])
y_race = np.array(dataframe['Race'])

class UTKFace(tf.keras.utils.Sequence):
    # Class is a dataset wrapper for better training performance
    def __init__(self, x_set, y_set, batch_size):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size
        self.datalen = len(x_set)
        self.indices = np.arange(self.x.shape[0])

    def __len__(self):
        return math.ceil(self.x.shape[0] / self.batch_size)

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) *
        self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) *
        self.batch_size]
        return batch_x, batch_y

    def on_epoch_end(self):
        self.indexes = np.arange(self.datalen)
        np.random.shuffle(self.indices)

UTK = UTKFace(X, np.array([y_race,y_gender]).T, 128)
print(UTK)

input_shape = (64, 64, 3)
input = Input((input_shape))

conv_1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(input)
maxp_1 = MaxPooling2D(pool_size=(2, 2))(conv_1)
conv_2 = Conv2D(64, kernel_size=(3, 3), activation='relu')(maxp_1)
maxp_2 = MaxPooling2D(pool_size=(2, 2)) (conv_2)
conv_3 = Conv2D(128, kernel_size=(3, 3), activation='relu')(maxp_2)
maxp_3 = MaxPooling2D(pool_size=(2, 2))(conv_3)
flatten = Flatten()(maxp_3)
dense = Dense(128, activation='relu')(flatten)
dropout = Dropout(0.3)(dense)
race_predicted = Dense(1, activation='sigmoid')(dropout)

race_model = Model(inputs=[input], outputs=[race_predicted])

d_input_shape = (1, 1)
d_input = Input(d_input_shape)

d_dense = Dense(1,activation='sigmoid')(Dense(256)(d_input))
d_output = Flatten()(d_dense)

d_model = Model(inputs = [d_input], outputs = [d_output])
d_model.compile(loss=['binary_crossentropy'], loss_weights=[1], optimizer=tf.keras.optimizers.Adam(0.0001), metrics=['acc'])

gan_output = d_model(race_model(input))
gan = Model(inputs=[input], outputs = [race_predicted, gan_output])
alpha = 0.01
gan.compile(loss=['binary_crossentropy','binary_crossentropy'], loss_weights = [1,-alpha], optimizer=tf.keras.optimizers.Adam(0.0001), metrics=['acc'])

## Training logic
num_epochs = 10
disc_metrics = []
gan_metrics = []

for epoch in range(num_epochs):
    historicala=[]
    historicald=[]
    step = 0

    for i,(x,y) in enumerate(UTK):
        step += 1
        race_out = race_model.predict(x);
        d_model.trainable = True
        historicald.append(d_model.train_on_batch(race_out,y[:,1]))
        d_model.trainable = False
        historicala.append(gan.train_on_batch(x,[y[:,0],1-y[:,1]]))
        if step >= 10:
          break
      
    disc_metrics.append(historicald)
    gan_metrics.append(historicala)
    print(disc_metrics)

xaxis = [1,2]
plt.plot(xaxis, disc_metrics[:][0].T)
plt.title("Discriminator Training")
plt.legend(labels=['Loss','Accuracy'])

plt.plot(xaxis, gan_metrics[:][0])
plt.legend(labels=['Loss','Race Out Loss','Model Loss','Race Out Accuracy','Model Accuracy'])
plt.title("GAN Training")